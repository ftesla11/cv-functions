{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "6a267008990d7b3f1d3ebce10cbcacbf117079c8bfe3a065af3a14fc1c0ce961"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *"
   ]
  },
  {
   "source": [
    "# Question 1 - Transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### create image with a name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ICV_create_name('Hai', 'Name')\n",
    "ICV_show_img(img, 'Name')"
   ]
  },
  {
   "source": [
    "## Question 1B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Rotate 30 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 30\n",
    "\n",
    "# perform rotation\n",
    "r_img = ICV_rotate(img, angle)\n",
    "\n",
    "# display output image after transformation\n",
    "ICV_show_img(r_img, 'Rotated {}'.format(angle))\n",
    "cv2.imwrite('figures/transformations/rotate{}.jpg'.format(angle), r_img)"
   ]
  },
  {
   "source": [
    "### Rotate 60 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 60\n",
    "\n",
    "# perform rotation\n",
    "r_img = ICV_rotate(img, angle)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(r_img, 'Rotated {}'.format(angle))\n",
    "cv2.imwrite('figures/transformations/rotate{}.jpg'.format(angle), r_img)"
   ]
  },
  {
   "source": [
    "### Rotate 120 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 120\n",
    "\n",
    "# perform rotation\n",
    "r_img = ICV_rotate(img, angle)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(r_img, 'Rotated {}'.format(angle))\n",
    "cv2.imwrite('figures/transformations/rotate{}.jpg'.format(angle), r_img)"
   ]
  },
  {
   "source": [
    "### Rotate -50 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = -50\n",
    "\n",
    "# perform rotation\n",
    "r_img = ICV_rotate(img, angle)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(r_img, 'Rotated {}'.format(angle))\n",
    "cv2.imwrite('figures/transformations/rotate{}.jpg'.format(angle), r_img)"
   ]
  },
  {
   "source": [
    "### Skew 10 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 10\n",
    "\n",
    "# perform skewing\n",
    "skewed_img = ICV_skew(img, angle)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(skewed_img, 'Skewed')\n",
    "cv2.imwrite('figures/transformations/skew{}.jpg'.format(angle), skewed_img)"
   ]
  },
  {
   "source": [
    "### Skew 40 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 40\n",
    "\n",
    "# perform skewing\n",
    "skewed_img = ICV_skew(img, angle)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(skewed_img, 'Skewed')\n",
    "cv2.imwrite('figures/transformations/skew{}.jpg'.format(angle), skewed_img)"
   ]
  },
  {
   "source": [
    "### Skew 60 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 60\n",
    "\n",
    "# perform skewing\n",
    "skewed_img = ICV_skew(img, angle)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(skewed_img, 'Skewed')\n",
    "cv2.imwrite('figures/transformations/skew{}.jpg'.format(angle), skewed_img)"
   ]
  },
  {
   "source": [
    "## Question 1C"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Rotate 20 degrees then skew 50 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform rotation\n",
    "new_img = ICV_rotate(img, 20)\n",
    "\n",
    "# perform skewing on the new image\n",
    "new_img = ICV_skew(new_img, 50)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(new_img, 'rotate20_skew50.jpg')\n",
    "cv2.imwrite('figures/transformations/rotate20_skew50.jpg', new_img)"
   ]
  },
  {
   "source": [
    "### Skew 50 degrees then rotate 20 degrees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform skewing\n",
    "new_img = ICV_skew(img, 50)\n",
    "\n",
    "# perform rotation\n",
    "new_img = ICV_rotate(new_img, 20)\n",
    "\n",
    "# display output image\n",
    "ICV_show_img(new_img, 'skew50_rotate20.jpg')\n",
    "cv2.imwrite('figures/transformations/skew50_rotate20.jpg', new_img)"
   ]
  },
  {
   "source": [
    "# Question 2 - Convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Dataset/DatasetA/car-1.jpg')"
   ]
  },
  {
   "source": [
    "## Question 2B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Initialisation of kernel for Average Intensity Convolution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kernel for computing average of neighbors\n",
    "kernel_mean = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "# normalise\n",
    "kernel_mean = kernel_mean/kernel_mean.size\n",
    "\n",
    "# apply convolution\n",
    "mean_img = ICV_apply_kernel(img, kernel_mean)\n",
    "ICV_show_img(mean_img, 'Mean Filter')\n",
    "cv2.imwrite('figures/convolutions/average_intensity.jpg', mean_img)"
   ]
  },
  {
   "source": [
    "## Question 2C"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Initialisation of Kernel A and kernel B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel A\n",
    "kernel_A = np.array([\n",
    "    [1, 2, 1],\n",
    "    [2, 4, 2],    \n",
    "    [1, 2, 1]\n",
    "])\n",
    "\n",
    "# normalise kernel A\n",
    "sum_A = np.sum(kernel_A)\n",
    "kernel_A = kernel_A/sum_A\n",
    "\n",
    "# kernel B\n",
    "kernel_B = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, -4, 1],\n",
    "    [0, 1, 0]\n",
    "])"
   ]
  },
  {
   "source": [
    "### Apply Kernel A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply convolution with kernel A\n",
    "A_img = ICV_apply_kernel(img, kernel_A)\n",
    "ICV_show_img(A_img, 'Kernel A')\n",
    "cv2.imwrite('figures/convolutions/img_A.jpg', A_img)"
   ]
  },
  {
   "source": [
    "### Apply Kernel B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply convolution with kernel B\n",
    "B_img = ICV_apply_kernel(img, kernel_B)\n",
    "ICV_show_img(B_img, 'Kernel B')\n",
    "cv2.imwrite('figures/convolutions/img_B.jpg', B_img)"
   ]
  },
  {
   "source": [
    "## Question 2D"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Kernel A followed by kernel A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply convolution with Kernel A\n",
    "A_A = ICV_apply_kernel(img, kernel_A)\n",
    "\n",
    "# apply convolution with kernel A for a second time\n",
    "A_A = ICV_apply_kernel(A_A, kernel_A)\n",
    "ICV_show_img(A_A, 'img_AA')\n",
    "cv2.imwrite('figures/convolutions/img_AA.jpg', A_A)"
   ]
  },
  {
   "source": [
    "### Kernel A followed by kernel B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply convolution with kernel A\n",
    "A_B = ICV_apply_kernel(img, kernel_A)\n",
    "\n",
    "# apply convolution with kernel B\n",
    "A_B = ICV_apply_kernel(A_B, kernel_B)\n",
    "ICV_show_img(A_B, 'img_AB')\n",
    "cv2.imwrite('figures/convolutions/img_AB.jpg', A_B)"
   ]
  },
  {
   "source": [
    "### Kernel B followed by kernel A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply convolution with kernel B\n",
    "B_A = ICV_apply_kernel(img, kernel_B)\n",
    "\n",
    "# apply convolution with kernel A\n",
    "B_A = ICV_apply_kernel(B_A, kernel_A)\n",
    "ICV_show_img(B_A, 'img_BA')\n",
    "cv2.imwrite('figures/convolutions/img_BA.jpg', B_A)"
   ]
  },
  {
   "source": [
    "# Question 3 - Histogram and Video Segmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Question 3A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/DatasetB.avi'"
   ]
  },
  {
   "source": [
    "### Get frames from video sequence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ICV_get_frames(path, 1)"
   ]
  },
  {
   "source": [
    "### Save the frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('figures/histogram/first_frame.png', frames[0])\n",
    "cv2.imwrite('figures/histogram/second_frame.png', frames[1])\n",
    "cv2.imwrite('figures/histogram/last_frame.png', frames[len(frames)-1])"
   ]
  },
  {
   "source": [
    "### Create histograms for consecutive and non-consecutive frames in a video sequence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate histogram for first frame of the video sequence\n",
    "first_histogram = ICV_create_hist(frames[0])\n",
    "\n",
    "# plot and save the histogram for the first frame\n",
    "ICV_plot_histogram(first_histogram, 'figures/histogram/first_histogram.png')\n",
    "\n",
    "# generate histogram for second frame of the video sequence\n",
    "second_histogram = ICV_create_hist(frames[1])\n",
    "\n",
    "# plot and save the histogram for the second frame\n",
    "ICV_plot_histogram(second_histogram, 'figures/histogram/second_histogram.png')\n",
    "\n",
    "# generate histogram for last frame of the video sequence\n",
    "last_histogram = ICV_create_hist(frames[len(frames)-1])\n",
    "\n",
    "# plot and save the histogram for the last frame\n",
    "ICV_plot_histogram(last_histogram, 'figures/histogram/last_histogram.png')"
   ]
  },
  {
   "source": [
    "## Question 3B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Histogram intersection of non-consecutive frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histogram intersection for first frame and last frame\n",
    "non_consecutive_intersection = ICV_hist_intersection(first_histogram, last_histogram)\n",
    "non_consecutive_intersection"
   ]
  },
  {
   "source": [
    "### Histogram intersection of consecutive frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histogram intersection for first frame and second frame\n",
    "consecutive_intersection = ICV_hist_intersection(first_histogram, second_histogram)\n",
    "consecutive_intersection"
   ]
  },
  {
   "source": [
    "### Histogram intersections of a video sequence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute histogram intersections for all colour channels in the video sequence over time\n",
    "blue_intersections = ICV_get_intersections(frames, 0)\n",
    "green_intersections = ICV_get_intersections(frames, 1)\n",
    "red_intersections = ICV_get_intersections(frames, 2)"
   ]
  },
  {
   "source": [
    "### Normalized histogram intersections"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pixels = np.array(frames).shape[1] * np.array(frames).shape[2]\n",
    "\n",
    "# normalize the intersections obtained from previous cell\n",
    "blue_normalized = ICV_normalize_intersections(blue_intersections, number_of_pixels)\n",
    "red_normalized = ICV_normalize_intersections(red_intersections, number_of_pixels)\n",
    "green_normalized = ICV_normalize_intersections(green_intersections, number_of_pixels)\n"
   ]
  },
  {
   "source": [
    "### Bar graph of histogram intersections"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_plot_intersections(frames, (blue_intersections, green_intersections, red_intersections), 'bar', 'figures/histogram/video_intersection_bar.png')"
   ]
  },
  {
   "source": [
    "### Line graph of normalized histogram intersections"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_plot_intersections(frames, (blue_intersections, green_intersections, red_intersections), 'line', 'figures/histogram/video_intersection_line.png')"
   ]
  },
  {
   "source": [
    "### Line graph of histogram intersections"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_plot_intersections(frames, (blue_normalized, green_normalized, red_normalized), 'bar', 'figures/histogram/video_intersection_normalized_bar.png')"
   ]
  },
  {
   "source": [
    "### Line graph of normalized histogram intersections"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_plot_intersections(frames, (blue_normalized, green_normalized, red_normalized), 'line', 'figures/histogram/video_intersection_normalized_line.png')"
   ]
  },
  {
   "source": [
    "# Question 4 - Texture Descriptors and Classification\n",
    "# DON'T MARK THIS YET "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split image into windows\n",
    "def to_windows(img):\n",
    "    window_size = 3\n",
    "    x, y = img.shape[0], img.shape[1]\n",
    "\n",
    "    windows = []\n",
    "\n",
    "    for i in range(0, x,  window_size):\n",
    "        for j in range(0, y, window_size):\n",
    "            window = img[i:i+window_size, j:j+window_size]\n",
    "            windows.append(window)\n",
    "    return windows\n",
    "\n",
    "\n",
    "# apply local binary pattern\n",
    "def apply_lbp(img):\n",
    "\n",
    "    # Add border to apply for edge pixels\n",
    "    img = to_grayscale(img)\n",
    "#    img = add_border(img)\n",
    "\n",
    "    x, y = img.shape[0], img.shape[1]\n",
    "    new_img = np.empty((x, y, 1), dtype=np.uint8)\n",
    "\n",
    "    for i in range(1, x-1):\n",
    "        for j in range(1, y-1):\n",
    "\n",
    "            # Compare center pixel to neighborhood\n",
    "            center = img[i, j].astype(int)\n",
    "            nw = 0 if center > img[i-1, j-1] else 1\n",
    "            n = 0 if center > img[i-1, j] else 1\n",
    "            ne = 0 if center > img[i-1, j+1] else 1\n",
    "            e = 0 if center > img[i, j+1] else 1\n",
    "            se = 0 if center > img[i+1, j+1] else 1\n",
    "            s = 0 if center > img[i+1, j] else 1\n",
    "            sw = 0 if center > img[i+1, j-1] else 1\n",
    "            w = 0 if center > img[i, j-1] else 1\n",
    "\n",
    "            # Bit code of the neighbors\n",
    "            binary_string = [ne, e, se, s, sw, w, nw, n]\n",
    "            decimal = 0\n",
    "\n",
    "            # Converrt to decimal\n",
    "            for k, bit in enumerate(binary_string):\n",
    "                decimal += bit*(2**k)\n",
    "\n",
    "            new_img[i, j] = decimal\n",
    "    intensity, count = np.unique(new_img[:, :], return_counts=True)\n",
    "    intensity, count = fill_intensities(intensity, count)\n",
    "    return (count)\n",
    "\n",
    "def get_fd(img):\n",
    "    img = add_border(img)\n",
    "   # img = to_grayscale(img)\n",
    "    windows = to_windows(img)\n",
    "\n",
    "    fds = []\n",
    "\n",
    "    for window in windows:\n",
    "        lbp = apply_lbp(window)\n",
    "        intensity, count = np.unique(lbp, return_counts=True)\n",
    "        intensity, count = fill_intensities(intensity, count)\n",
    "        fds.append(count)\n",
    "    return fds\n",
    "\n",
    "def get_gd(windows):\n",
    "    windows = np.array(windows)\n",
    "    for i, window in enumerate(windows):\n",
    "        if i==0:\n",
    "            gd = window\n",
    "        else:\n",
    "            gd = np.concatenate((gd, window), axis=None)\n",
    "    return np.array(gd, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_descriptor(windows):\n",
    "    for i, window in enumerate(windows):\n",
    "        lbp = apply_lbp(window)\n",
    "        if i==0:\n",
    "            lbp_descriptors = lbp\n",
    "        else:\n",
    "            lbp_descriptors = np.concatenate((lbp_descriptors, lbp), axis=None)\n",
    "    return (np.array(lbp_descriptors, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Dataset/DatasetA/car-3.jpg')\n",
    "windows = to_windows(img)\n",
    "global_descriptor = get_global_descriptor(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('Dataset/DatasetA/car-2.jpg')\n",
    "windows2 = to_windows(img2)\n",
    "global_descriptor2 = get_global_descriptor(windows2)\n",
    "intersection1 = hist_intersection(global_descriptor, global_descriptor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('Dataset/DatasetA/car-2.jpg')\n",
    "windows2 = get_fd(img2)\n",
    "gd = get_gd(windows2)\n",
    "intersection1 = hist_intersection(global_descriptor, gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.imread('Dataset/DatasetA/car-1.jpg')\n",
    "windows3 = get_fd(img3)\n",
    "global_descriptor3 = get_gd(windows3)\n",
    "intersection2 = hist_intersection(global_descriptor, global_descriptor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = cv2.imread('Dataset/DatasetA/face-1.jpg')\n",
    "windows4 = get_fd(img4)\n",
    "global_descriptor4 = get_gd(windows4)\n",
    "intersection3 = hist_intersection(global_descriptor, global_descriptor4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img5 = cv2.imread('Dataset/DatasetA/face-2.jpg')\n",
    "windows5 = get_fd(img5)\n",
    "global_descriptor5 = get_gd(windows5)\n",
    "intersection4 = hist_intersection(global_descriptor, global_descriptor5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img6 = cv2.imread('Dataset/DatasetA/face-3.jpg')\n",
    "windows6 = get_fd(img6)\n",
    "global_descriptor6 = get_gd(windows6)\n",
    "intersection5 = hist_intersection(global_descriptor, global_descriptor6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5C\n",
    "def get_background(frames):\n",
    "    frames = np.array(frames)\n",
    "    x, y, z = frames.shape[1], frames.shape[2], frames.shape[3]\n",
    "\n",
    "    avg = np.zeros((x, y, z), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            avg[i, j] = np.mean(frames[:, i, j]) if z==1 else np.mean(frames[:, i, j, :])\n",
    "    return avg\n",
    "\n",
    "def get_frames(path, rbg):\n",
    "    vid = cv2.VideoCapture(path)\n",
    "\n",
    "    if (vid.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while(vid.isOpened()):\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        if ret==True:\n",
    "            if rbg==0:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                frame = frame[:, :, np.newaxis]\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break   \n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames\n",
    "\n",
    "def play_video(frames):\n",
    "    for frame in frames:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    pass\n",
    "\n",
    "# 5A\n",
    "def compute_segmentation(frames, reference_frame, threshold):\n",
    "    frames = np.array(frames)\n",
    "    \n",
    "    new_frames = []\n",
    "            \n",
    "    for frame in frames:\n",
    "        new_frame = np.abs(frame.astype('int16') - reference_frame.astype('int16'))\n",
    "        new_frame[new_frame < threshold] = 0\n",
    "        new_frame[new_frame > threshold] = 255\n",
    "        new_frames.append(new_frame)\n",
    "    new_frames = np.array(new_frames, dtype=np.uint8)\n",
    "    return new_frames\n",
    "\n",
    "# 5B\n",
    "def segment_previous_frame(frames, threshold):\n",
    "    frames = np.array(frames)\n",
    "\n",
    "    new_frames = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        if i==0:\n",
    "            new_frames.append(frame)\n",
    "            continue\n",
    "        new_frame = np.abs(frame.astype('int16') - frames[i-1].astype('int16'))\n",
    "        new_frame[new_frame < threshold] = 0\n",
    "        new_frame[new_frame > threshold] = 255\n",
    "        new_frames.append(new_frame)\n",
    "    new_frames = np.array(new_frames, dtype=np.uint8)\n",
    "    return new_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/DatasetC.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_frames(path, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_frame = get_background(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_show_img(reference_frame, 'bg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmented_frames = compute_segmentation(frames, reference_frame, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(segmented_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_show_img(frames[0], '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_show_img(segmented_frames[0], '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_fill_blobs(img, n):\n",
    "    x, y = img.shape[0], img.shape[1]\n",
    "    new_img = img.copy()\n",
    "\n",
    "    for i in range(x-1):\n",
    "        for j in range(y-1):\n",
    "            if img[i, j] == 0:\n",
    "                if img[i, j+1] == 255 or img[i, j-1] == 255 or img[i+1, j] == 255 or img[i+1, j+1] == 255 or img[i+1, j-1] == 255 or img[i-1, j] == 1 or img[i-1, j+1] == 255 or img[i-1, j-1] == 255:\n",
    "                    new_img[i, j] = 255\n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filled = segmented_frames[0].copy()\n",
    "for i in range(7):\n",
    "    filled = ICV_fill_blobs(filled, 1)\n",
    "ICV_show_img(filled, '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#flatten to make greyscale, using your second red-black image as input.\n",
    "#im = scipy.misc.imread('blobs.jpg',flatten=1)\n",
    "#smooth and threshold as image has compression artifacts (jpg)\n",
    "\n",
    "im = ndimage.gaussian_filter(filled, 1)\n",
    "blobs, count = ndimage.label(im)\n",
    "print('Number of blobs:', count)\n",
    "\n",
    "plt.imshow(blobs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_frames2 = segment_previous_frame(frames, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(segmented_frames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICV_show_img(segmented_frames2[1], 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}